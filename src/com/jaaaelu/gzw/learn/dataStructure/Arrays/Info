通过时间复杂度来查看动态数组的性能

简单的时间复杂度分析

比如我们经常能看到 O(1) O(n) O(lgn) O(nlogn) O(n^2)
简单的来说：大 O 描述的时算法的运行时间和输入数据之间的关系

例如下面这段代码：

    private static void sum(int[] nums) {
        int sum = 0;
        for (int num : nums) {
            sum += num;
        }
    }

它的时间复杂度为 O(n)，n 这里值的是数组 nums 中的元素个数，所以这个 O(n) 的意思是说这个算法的运行的时间多少是和 nums 中的元素个数呈线性关
系，这里的线性关系就表现在这里的 n 是一次方的（也即是算法和 n 呈线性关系）
为什么要用大 O，叫做 O(n)？因为这里忽略了常数，实际时间 T = c1 * n + c2，这里做累加不仅要做遍历还有进行叠加计算
所以：
    T = 2 * n + 2
    T = 2000 * n + 2000
他们都是 O(n) 的线性复杂度
如果是 T = 1 * n * n + 2，那么就是 O(n^2) 级别的算法
但并不是 O(n) 的算法在任何时候都快于 O(n^2) 的算法
O 的算法复杂度表示的是渐进时间复杂度，实际上描述 n 趋近于无穷的情况，谁快谁慢

分析动态数组的时间复杂度：
1.添加操作（综合来看是 O(n)，我们需要关注最坏的情况，resize 也是 O(n) 的）
- addLast(value) O(1)，O(1) 表示我们的耗时操作和我们的数组大小是没有关系的
- addFirst(value) O(n)，要向第一个元素添加值就会导致后续元素全部需要往后移一位
- add(index, e) O(n/2) = O(n)，因为 index 可能为 0 ～ size 的任意一个，向前一些耗的时间久一些，向后一些耗的时间短一些
2.删除操作（综合来看是 O(n)，我们需要关注最坏的情况，resize 也是 O(n) 的）
- removeLast() O(1)
- removeFirst() O(n)
- remove(index, e) O(n/2) = O(n)
3.修改操作
- set(index, value) O(1)
4.查询操作
- get(index) O(1)
- contains(value) O(n)
- find(value) O(n)

综上动态数组的时间复杂度
- 增：O(n)
- 删：O(n)
- 改：已知索引O(1)，未知索引O(n)
- 查：已知索引O(1)，未知索引O(n)


均摊复杂度
重新分析 resize() 的时间复杂度
假设 capacity = 8，并且每一次添加操作都使用 addLast(value)，那么添加 8 次后的第九次才会 resize() 一次
9 次 addLast 操作，触发 resize，总共进行了 17（第九次是 8 + 1） 次基本操作（赋值）
平均，每次 addLast 操作，进行 2 次操作

故假设 capacity = n，n + 1 次 addLast，才会触发 resize，总共进行了 2n + 1 次操作
平均，每次 addLast 操作，进行 2 次基本操作
这样平摊计算下来，addLast 的时间复杂度是 O(1)，所以 addLast 的操作也就和数组里一共有多少元素是没有关系的
在这个例子中，这样均摊计算，比计算最坏情况有意义，这里的计算就是均摊复杂度

也就是说一个相对耗时的操作如果可以保证并不会每次都调用，那么相应的时间可以分摊到其他操作中的
所以对应来看 removeLast 的均摊复杂度其实也是 O(1) 的


复杂度震荡
假设 capacity = n，正好这时数组满了，我调用 addLast 后会扩容(O(n))，再调用 removeLast 也会缩容(O(n))，再调用调用 addLast 又会进行扩
容(O(n))，妈的没想到我又调用了 removeLast 这里又进行了缩容(O(n))
正常情况下，我们调用 addLast 和 removeLast 是每隔 n 才会进行 resize，resize 的时间复杂度为 O(n)，但现在我们制造了一种情景，使得每次调
用都会扩容，明明在复杂度均摊的情况下挺好，但是特殊的情况的复杂度就会猛的窜到 O(n) 这个级别

出现问题的原因：removeLast 时 resize 过于着急，现在逻辑时一旦有效长度为容量的二分之一时，我们就将数组容量修改为容量二分之一，这时我们不应
该让判断的有效长度和缩容后的长度相等
解决方案：Lazy，防止复杂度震荡，当有效长度为容量四分之一时，才将容量减半

有时候我们算法懒一些，反而性能会更好一些












